{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r\"\\w+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read corpus\n",
    "text = words(open('ind_news_2012_300K-sentences.txt',encoding='utf8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter words for bigram\n",
    "WORDS_2 = Counter(zip(text, it.islice(text, 1, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter words for unigram\n",
    "WORDS = Counter(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple edit : to a word is a deletion, a transposition, a replacement or an insertion\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words that are knownâ€”that is, in the dictionary\n",
    "def known(words): return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 x simple edit : to a word is a deletion, a transposition, a replacement or an insertion\n",
    "def edits2(word): return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word candidate list from error word \n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability for unigram\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability for bigram, given two words\n",
    "def P2(words, N=sum(WORDS_2.values())):\n",
    "    V = len(WORDS.values())\n",
    "    \"Probability of two `words --> for bigram`.\"\n",
    "    #P(B|A) =  C(A|B) + 1/P(B) + V #with smoothing\n",
    "    return ((WORDS_2[words[0], words[1]]/N)+1)/(P(words[0]) + V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a correction word for unigram\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    # a corection word will be chosen from the words candidate which has max probability\n",
    "    return max(candidates(word), key=P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a correction word for bigram\n",
    "def correction_2(words):\n",
    "    #check candidate list\n",
    "    word_candidates = list(candidates(words[1]))\n",
    "    #temp -> index of candidate list which has bigger probability\n",
    "    max_index = 0\n",
    "    #temp -> current max probability\n",
    "    max_prob = 0\n",
    "    #iterating candidate list (find max probability)\n",
    "    for index, word in enumerate(word_candidates):\n",
    "        if P2([words[0], word])*P2([word, words[2]]) > max_prob :\n",
    "            max_index = index\n",
    "            #P(b, a)*p(a, c)\n",
    "            max_prob = P2([words[0], word])*P2([word, words[2]])\n",
    "    #high probability candidate will be chosen\n",
    "    return word_candidates[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling test for unigram \n",
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.perf_counter() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set function for given test data\n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right, wrong)\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17% of 225 correct (53% unknown) at 35 words per second \n"
     ]
    }
   ],
   "source": [
    "# unigram testing\n",
    "spelltest(Testset(open('testset.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling test for bigram\n",
    "def spelltest_2(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction_2(wrong)\n",
    "        #delete white space\n",
    "        right = right.strip()\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = time.perf_counter() - start\n",
    "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set function for bigram by given test data\n",
    "def Testset2(lines):\n",
    "    #array of test set\n",
    "    array_test2 = []\n",
    "    for line in lines:\n",
    "        #the right words\n",
    "        right = (line.split(':')[0].lower())\n",
    "        #a sentence that need to be corected in the midle of word\n",
    "        wrong = (line.split(':')[1].rstrip().split())\n",
    "        #to lowercase\n",
    "        wrong = [word.lower() for word in wrong]\n",
    "        #add it to tuple\n",
    "        y = (right, wrong)\n",
    "        array_test2.append(y)\n",
    "    return array_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25% of 16 correct (0% unknown) at 2367 words per second \n"
     ]
    }
   ],
   "source": [
    "# bigram testing using my own dataset\n",
    "spelltest_2(Testset2(open('testset2.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram perform more accurately than unigram\n",
    "#because in bigram not just cosidering one word itself\n",
    "#but In bigram we consider past one word and the next word\n",
    "#so from the bigram language model, we can get the context of the word that needs a correction, and corected it more accurately "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}